{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Machine_Learning"
      ],
      "metadata": {
        "id": "sY4IzVbhCIg0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer 1:\n",
        "Imagine you have a dataset where you have different Instagram features\n",
        "like username , Caption , Hashtag , Followers , Time_Since_posted , and likes , now your task is to predict the number of likes and Time Since posted and the rest of the features are\n",
        "your input features. Now you have to build a model which can predict the\n",
        "number of likes and Time Since posted.\n",
        "This is the Dataset You can use this dataset for this question.\n",
        "https://www.kaggle.com/datasets/rxsraghavagrawal/instagram-reach\n"
      ],
      "metadata": {
        "id": "J-OhKhUeCOmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import re\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('instagram_reach.csv')\n",
        "\n",
        "# Preprocess the data\n",
        "# Remove unnecessary columns\n",
        "df = df.drop(['S.No', 'USERNAME', 'Caption', 'Hashtags'], axis=1)\n",
        "\n",
        "# Handle missing values if any\n",
        "df = df.dropna()\n",
        "\n",
        "# Convert \"Time since posted\" column to numeric\n",
        "def extract_numeric_value(time_str):\n",
        "    numeric_str = re.findall(r'\\d+', time_str)[0]\n",
        "    return float(numeric_str)\n",
        "\n",
        "df['Time since posted'] = df['Time since posted'].apply(extract_numeric_value)\n",
        "\n",
        "# Split the dataset into input features (X) and target variables (y)\n",
        "X = df.drop(['Likes', 'Time since posted'], axis=1)\n",
        "y_likes = df['Likes']\n",
        "y_time_since_posted = df['Time since posted']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train_likes, y_test_likes, y_train_time, y_test_time = train_test_split(X, y_likes, y_time_since_posted, test_size=0.2, random_state=42)\n",
        "\n",
        "# Choose a suitable machine learning algorithm (e.g., Linear Regression)\n",
        "model_likes = LinearRegression()\n",
        "model_time_since_posted = LinearRegression()\n",
        "\n",
        "# Train the model on the training data\n",
        "model_likes.fit(X_train, y_train_likes)\n",
        "model_time_since_posted.fit(X_train, y_train_time)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred_likes = model_likes.predict(X_test)\n",
        "y_pred_time_since_posted = model_time_since_posted.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "mse_likes = mean_squared_error(y_test_likes, y_pred_likes)\n",
        "mae_likes = mean_absolute_error(y_test_likes, y_pred_likes)\n",
        "\n",
        "mse_time_since_posted = mean_squared_error(y_test_time, y_pred_time_since_posted)\n",
        "mae_time_since_posted = mean_absolute_error(y_test_time, y_pred_time_since_posted)\n",
        "\n",
        "print(\"Likes - Mean Squared Error:\", mse_likes)\n",
        "print(\"Likes - Mean Absolute Error:\", mae_likes)\n",
        "\n",
        "print(\"Time Since Posted - Mean Squared Error:\", mse_time_since_posted)\n",
        "print(\"Time Since Posted - Mean Absolute Error:\", mae_time_since_posted)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BVa1RQp3ePk",
        "outputId": "292e2661-65b9-4cf0-c99b-3e2507c79ec4"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Likes - Mean Squared Error: 1177.6386214536167\n",
            "Likes - Mean Absolute Error: 25.50251318640826\n",
            "Time Since Posted - Mean Squared Error: 11.413093536823258\n",
            "Time Since Posted - Mean Absolute Error: 2.1757250175200777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer 2:\n",
        " Imagine you have a dataset where you have different features like Age ,Gender , Height , Weight , BMI , and Blood Pressure and you have to classify the people into\n",
        "different classes like Normal , Overweight , Obesity , Underweight , and Extreme Obesity by using\n",
        "any 4 different classification algorithms. Now you have to build a model which\n",
        "can classify people into different classes.\n",
        "https://www.kaggle.com/datasets/ankurbajaj9/obesity-levels \n",
        "This is the Dataset You can use this dataset for this question.\n"
      ],
      "metadata": {
        "id": "A_JXwdLmGi68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('ObesityDataSet_raw_and_data_sinthetic.csv')\n",
        "\n",
        "# Convert categorical variables into numerical using one-hot encoding\n",
        "df = pd.get_dummies(df, columns=['Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE', 'SCC', 'CALC', 'MTRANS'])\n",
        "\n",
        "# Binary encoding for the 'NCP' column\n",
        "df['NCP'] = df['NCP'].apply(lambda x: 1 if x == 'yes' else 0)\n",
        "\n",
        "#Split the dataset into training and testing sets\n",
        "X = df.drop('NObeyesdad', axis=1)\n",
        "y = df['NObeyesdad']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Decision Tree classifier\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the testing dataset\n",
        "y_pred_dt = dt.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of Decision Tree classifier\n",
        "print(\"Decision Tree Classifier Performance:\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_dt))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_dt))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZ1KbT2JHlqs",
        "outputId": "65d5e1ec-d54d-4595-be73-95e76712272e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classifier Performance:\n",
            "Confusion Matrix:\n",
            "[[55  1  0  0  0  0  0]\n",
            " [ 4 55  0  0  0  3  0]\n",
            " [ 0  0 73  4  0  0  1]\n",
            " [ 0  0  2 55  0  0  1]\n",
            " [ 0  0  0  0 63  0  0]\n",
            " [ 0  5  0  0  0 49  2]\n",
            " [ 0  0  0  0  0  2 48]]\n",
            "Classification Report:\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "Insufficient_Weight       0.93      0.98      0.96        56\n",
            "      Normal_Weight       0.90      0.89      0.89        62\n",
            "     Obesity_Type_I       0.97      0.94      0.95        78\n",
            "    Obesity_Type_II       0.93      0.95      0.94        58\n",
            "   Obesity_Type_III       1.00      1.00      1.00        63\n",
            " Overweight_Level_I       0.91      0.88      0.89        56\n",
            "Overweight_Level_II       0.92      0.96      0.94        50\n",
            "\n",
            "           accuracy                           0.94       423\n",
            "          macro avg       0.94      0.94      0.94       423\n",
            "       weighted avg       0.94      0.94      0.94       423\n",
            "\n",
            "Accuracy: 0.9408983451536643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Random Forest classifier\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the testing dataset\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of Random Forest classifier\n",
        "print(\"Random Forest Classifier Performance:\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_rf))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Cb2oZt-e5LW",
        "outputId": "bfe8370c-98b5-45d5-d23f-eaa52e53e168"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier Performance:\n",
            "Confusion Matrix:\n",
            "[[54  2  0  0  0  0  0]\n",
            " [ 1 57  0  0  0  3  1]\n",
            " [ 0  2 72  2  0  1  1]\n",
            " [ 0  0  1 57  0  0  0]\n",
            " [ 0  0  0  0 63  0  0]\n",
            " [ 0  6  0  0  0 49  1]\n",
            " [ 0  0  0  0  0  2 48]]\n",
            "Classification Report:\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "Insufficient_Weight       0.98      0.96      0.97        56\n",
            "      Normal_Weight       0.85      0.92      0.88        62\n",
            "     Obesity_Type_I       0.99      0.92      0.95        78\n",
            "    Obesity_Type_II       0.97      0.98      0.97        58\n",
            "   Obesity_Type_III       1.00      1.00      1.00        63\n",
            " Overweight_Level_I       0.89      0.88      0.88        56\n",
            "Overweight_Level_II       0.94      0.96      0.95        50\n",
            "\n",
            "           accuracy                           0.95       423\n",
            "          macro avg       0.95      0.95      0.95       423\n",
            "       weighted avg       0.95      0.95      0.95       423\n",
            "\n",
            "Accuracy: 0.9456264775413712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Naive Bayes classifier\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the testing dataset\n",
        "y_pred_nb = nb.predict(X_test)\n",
        "\n",
        "# Evaluate the performance ofNaive Bayes classifier\n",
        "print(\"Naive Bayes Classifier Performance:\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_nb))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_nb))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTxDKCXhe5H6",
        "outputId": "a4a6edf6-18bf-4d5b-97da-6906883d12f0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Classifier Performance:\n",
            "Confusion Matrix:\n",
            "[[42  0 13  0  0  1  0]\n",
            " [35  8  5  0  1  7  6]\n",
            " [ 0  2 32 37  0  3  4]\n",
            " [ 0  0  0 56  0  0  2]\n",
            " [ 0  0  0  0 63  0  0]\n",
            " [15  2 20  6  0  8  5]\n",
            " [ 2  2 18 13  0  0 15]]\n",
            "Classification Report:\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "Insufficient_Weight       0.45      0.75      0.56        56\n",
            "      Normal_Weight       0.57      0.13      0.21        62\n",
            "     Obesity_Type_I       0.36      0.41      0.39        78\n",
            "    Obesity_Type_II       0.50      0.97      0.66        58\n",
            "   Obesity_Type_III       0.98      1.00      0.99        63\n",
            " Overweight_Level_I       0.42      0.14      0.21        56\n",
            "Overweight_Level_II       0.47      0.30      0.37        50\n",
            "\n",
            "           accuracy                           0.53       423\n",
            "          macro avg       0.54      0.53      0.48       423\n",
            "       weighted avg       0.54      0.53      0.49       423\n",
            "\n",
            "Accuracy: 0.5295508274231678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train Logistic Regression classifier\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Predict onthe testing dataset\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of Logistic Regression classifier\n",
        "print(\"Logistic Regression Classifier Performance:\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_lr))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2n-6XQume5CV",
        "outputId": "fa36e575-ed79-4f37-c30d-64b75b9f6ef1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Classifier Performance:\n",
            "Confusion Matrix:\n",
            "[[53  2  0  0  0  1  0]\n",
            " [16 26  1  2  0 11  6]\n",
            " [ 0  0 38 12  6  4 18]\n",
            " [ 0  0  4 53  0  0  1]\n",
            " [ 0  0  0  0 63  0  0]\n",
            " [ 2  4  6  1  0 32 11]\n",
            " [ 0  5 10  3  0  8 24]]\n",
            "Classification Report:\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "Insufficient_Weight       0.75      0.95      0.83        56\n",
            "      Normal_Weight       0.70      0.42      0.53        62\n",
            "     Obesity_Type_I       0.64      0.49      0.55        78\n",
            "    Obesity_Type_II       0.75      0.91      0.82        58\n",
            "   Obesity_Type_III       0.91      1.00      0.95        63\n",
            " Overweight_Level_I       0.57      0.57      0.57        56\n",
            "Overweight_Level_II       0.40      0.48      0.44        50\n",
            "\n",
            "           accuracy                           0.68       423\n",
            "          macro avg       0.67      0.69      0.67       423\n",
            "       weighted avg       0.68      0.68      0.67       423\n",
            "\n",
            "Accuracy: 0.6832151300236406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer 3:\n"
      ],
      "metadata": {
        "id": "WFPoLm60fsO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_json('/content/News_Category_Dataset_v3.json', lines=True)\n",
        "\n",
        "# Convert the headline and short_description columns to a single text column\n",
        "df['text'] = df['headline'] + ' ' + df['short_description']\n",
        "\n",
        "# Vectorize the text using TF-IDF\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(df['text'])\n",
        "\n",
        "# Build a k-nearest neighbors model using cosine similarity\n",
        "knn = NearestNeighbors(metric='cosine')\n",
        "knn.fit(X)\n",
        "\n",
        "# Define a function to find the most similar data to a given data point\n",
        "def find_similar_data(data_point, num_similar=5):\n",
        "    # Vectorize the given data point using the same vectorizer\n",
        "    x_query = vectorizer.transform([data_point])\n",
        "    # Find the k-nearest neighbors based on cosine similarity\n",
        "    distances, indices = knn.kneighbors(x_query, n_neighbors=num_similar)\n",
        "    # Return the most similar data points\n",
        "    return df.iloc[indices[0]]['text']\n",
        "\n",
        "# Example usage\n",
        "query = 'President Biden announces new infrastructure plan'\n",
        "similar_data = find_similar_data(query)\n",
        "similar_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfL0qQG5e46h",
        "outputId": "8d34e6cf-62a8-4481-992e-8114cdca4d80"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14467    Trump's New Infrastructure Plan Is Kind Of Und...\n",
              "2675     White House Offers GOP $1.7 Trillion Infrastru...\n",
              "50537    Trump's Infrastructure Plan Dwarfed By Estimat...\n",
              "40282    Trumpâ€™s Infrastructure Promise Is Leaving Out ...\n",
              "18511    Donald Trump Prepares To Finally Release His I...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer 4:"
      ],
      "metadata": {
        "id": "1qObu5V7iGAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('online_shoppers_intention.csv')\n",
        "\n",
        "# Preprocess the data\n",
        "le = LabelEncoder()\n",
        "ohe = OneHotEncoder()\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Encode categorical variables using one-hot encoding\n",
        "df = pd.get_dummies(df, columns=['Month', 'VisitorType'])\n",
        "\n",
        "# Encode the Weekend variable as binary (0 or 1)\n",
        "df['Weekend'] = le.fit_transform(df['Weekend'])\n",
        "\n",
        "# Scale numerical variables\n",
        "df[['Administrative', 'Administrative_Duration', 'Informational', 'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration', 'BounceRates', 'ExitRates', 'PageValues']] = scaler.fit_transform(df[['Administrative', 'Administrative_Duration', 'Informational', 'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration', 'BounceRates', 'ExitRates', 'PageValues']])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X = df.drop(['Revenue'], axis=1)\n",
        "y = df['Revenue']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a set of base classifiers\n",
        "clf_rf = RandomForestClassifier()\n",
        "clf_gb = GradientBoostingClassifier()\n",
        "\n",
        "# Train the base classifiers on the training set\n",
        "clf_rf.fit(X_train, y_train)\n",
        "clf_gb.fit(X_train, y_train)\n",
        "\n",
        "# Use the base classifiers to make predictions on the testing set\n",
        "y_pred_rf = clf_rf.predict(X_test)\n",
        "y_pred_gb = clf_gb.predict(X_test)\n",
        "\n",
        "# Combine the predictions using an ensemble voting classifier\n",
        "ensemble = VotingClassifier(estimators=[('rf', clf_rf), ('gb', clf_gb)], voting='hard')\n",
        "ensemble.fit(X_train, y_train)\n",
        "y_pred_ensemble = ensemble.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the ensemble model\n",
        "print('Random Forest Classifier:')\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred_rf))\n",
        "print('Precision:', precision_score(y_test, y_pred_rf))\n",
        "print('Recall:', recall_score(y_test, y_pred_rf))\n",
        "print('F1 score:', f1_score(y_test, y_pred_rf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTqT__TtiPB5",
        "outputId": "6f27fcfb-03fd-46af-b5cd-fad369ee6ebb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier:\n",
            "Accuracy: 0.8933495539334956\n",
            "Precision: 0.7517006802721088\n",
            "Recall: 0.537712895377129\n",
            "F1 score: 0.626950354609929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Gradient Boosting Classifier:')\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred_gb))\n",
        "print('Precision:', precision_score(y_test, y_pred_gb))\n",
        "print('Recall:', recall_score(y_test, y_pred_gb))\n",
        "print('F1 score:', f1_score(y_test, y_pred_gb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYJOano2iRjX",
        "outputId": "5d6d3aa2-4e8e-4ca5-af39-c9c963da0d89"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Classifier:\n",
            "Accuracy: 0.8925385239253852\n",
            "Precision: 0.7172619047619048\n",
            "Recall: 0.5863746958637469\n",
            "F1 score: 0.64524765729585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Ensemble Voting Classifier:')\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred_ensemble))\n",
        "print('Precision:', precision_score(y_test, y_pred_ensemble))\n",
        "print('Recall:', recall_score(y_test, y_pred_ensemble))\n",
        "print('F1 score:', f1_score(y_test, y_pred_ensemble))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3XY8_HGjOei",
        "outputId": "b73a4565-7ed8-4a34-cf12-319cf5fe0260"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Voting Classifier:\n",
            "Accuracy: 0.8941605839416058\n",
            "Precision: 0.7757352941176471\n",
            "Recall: 0.51338199513382\n",
            "F1 score: 0.6178623718887263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer 5:"
      ],
      "metadata": {
        "id": "k8QaFrrBj9hl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/rideshare_kaggle.csv\")\n",
        "\n",
        "# Perform data preprocessing if needed\n",
        "\n",
        "# Unsupervised algorithm to predict high booking areas\n",
        "X = df[['latitude', 'longitude']]   # Features for clustering\n",
        "\n",
        "# Determine the optimal number of clusters using the elbow method\n",
        "wcss = []\n",
        "for i in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters=i, random_state=42)\n",
        "    kmeans.fit(X)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "plt.plot(range(1, 11), wcss)\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('WCSS')\n",
        "plt.title('Elbow Method')\n",
        "plt.show()\n",
        "\n",
        "# Choose the number of clusters and perform clustering\n",
        "n_clusters = 4\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "kmeans.fit(X)\n",
        "\n",
        "# Add the cluster labels to the dataset\n",
        "df['Cluster'] = kmeans.labels_\n",
        "\n",
        "# Display the clusters on a map using a library like folium\n",
        "# Your code for displaying the clusters on a map goes here\n",
        "\n",
        "# Supervised algorithm to predict price for location\n",
        "X = df[['latitude', 'longitude']]  # Features for regression\n",
        "y = df['price']  # Target variable\n",
        "\n",
        "# Handle missing values in the target variable\n",
        "y.fillna(y.mean(), inplace=True)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the price for the testing data\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        },
        "id": "dlPbjQu2_Yei",
        "outputId": "b9ed28b2-e5d7-432d-c928-b6d9ab0693f8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAHHCAYAAABeLEexAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABPYklEQVR4nO3deVxU9f4/8NeZgRkW2RFGlBAVXHFPI1fSxCW73TS/LpWVZQtminmVbipqhcvNTDO79rulddVs00rTxBVz1y5qqISKYOmAGwygbDPn9wfMwRHQQWc4s7yej8c84JzzmTnvA4/i5TmfRRBFUQQRERGRE1PIXQARERGR3BiIiIiIyOkxEBEREZHTYyAiIiIip8dARERERE6PgYiIiIicHgMREREROT0GIiIiInJ6DERERETk9BiIiMhiBEFAYmKitJ2YmAhBEHDlyhX5irJRTZs2xWOPPWb18+zatQuCIGDXrl1WPxeRPWMgIqI7WrlyJQRBqPV14MABuUu8Z02bNoUgCOjfv3+Nxz/99FPpOo8cOVLnzz958iQSExNx/vz5+6yUiKzNRe4CiMg+zJkzB+Hh4dX2t2jRQoZqLMfNzQ07d+6EVquFRqMxObZ69Wq4ubmhuLj4nj775MmTmD17Nvr27YumTZtaoFoishYGIiIyy6BBg9C1a1e5y7C4Hj164PDhw1i3bh3eeOMNaf+ff/6JPXv24O9//zu+++47GSskovrAR2ZEZHVXrlzBiBEj4O3tjYCAALzxxhvV7rqUl5dj7ty5aN68OdRqNZo2bYq33noLJSUlUpv4+HgEBARAFEVp3+uvvw5BELBkyRJpX05ODgRBwPLly+9am5ubG5588kmsWbPGZP/atWvh5+eH2NjYGt93+vRpDB8+HP7+/nBzc0PXrl3x448/SsdXrlyJp556CgAQExMjPXq7vS/Pr7/+im7dusHNzQ3NmjXDF198Ue1c586dw1NPPQV/f394eHjgoYcewqZNm6q1+/PPP/HEE0/A09MTQUFBmDx5ssnPj4hqx0BERGbJz8/HlStXTF5Xr141670jRoxAcXExkpKSMHjwYCxZsgTjx483afPiiy9i5syZ6Ny5Mz744AP06dMHSUlJGDlypNSmV69euHbtGtLS0qR9e/bsgUKhwJ49e0z2AUDv3r3Nqm/06NE4dOgQzp49K+1bs2YNhg8fDldX12rt09LS8NBDD+HUqVOYPn063n//fXh6euKJJ57A+vXrpXNPnDgRAPDWW2/hyy+/xJdffonWrVtLn3PmzBkMHz4cjz76KN5//334+fnhueeeM7m+nJwcPPzww/jll1/w2muv4d1330VxcTEef/xx6VwAcPPmTfTr1w+//PILJkyYgH/+85/Ys2cP/vGPf5j1MyByeiIR0R18/vnnIoAaX2q12qQtAHHWrFnS9qxZs0QA4uOPP27S7rXXXhMBiMeOHRNFURRTU1NFAOKLL75o0u7NN98UAYg7duwQRVEUc3NzRQDixx9/LIqiKObl5YkKhUJ86qmnxODgYOl9EydOFP39/UWDwXDHawsLCxOHDBkilpeXixqNRpw7d64oiqJ48uRJEYC4e/du6foPHz4sva9fv35iVFSUWFxcLO0zGAziww8/LEZEREj7vvnmGxGAuHPnzhrPDUBMSUmR9uXm5opqtVqcMmWKtG/SpEkiAHHPnj3SvoKCAjE8PFxs2rSpqNfrRVEUxcWLF4sAxK+//lpqV1RUJLZo0aLWGoioCu8QEZFZli1bhuTkZJPX5s2bzXpvXFycyfbrr78OAPj5559NvsbHx5u0mzJlCgBIj4caNmyIVq1aISUlBQCwd+9eKJVKTJ06FTk5OcjIyABQcYeoZ8+eEATBrPqUSiVGjBiBtWvXAqjoTB0aGopevXpVa3vt2jXs2LEDI0aMQEFBgcndstjYWGRkZOCvv/4y67xt2rQxOUfDhg3RsmVLnDt3Ttr3888/o1u3bujZs6e0r0GDBhg/fjzOnz+PkydPSu0aNWqE4cOHS+08PDyq3YkjopqxUzURmaVbt2733Kk6IiLCZLt58+ZQKBTScPSsrCwoFIpqI9Y0Gg18fX2RlZUl7evVq5cUoPbs2YOuXbuia9eu8Pf3x549exAcHIxjx45h9OjRdapx9OjRWLJkCY4dO4Y1a9Zg5MiRNQaqM2fOQBRFzJgxAzNmzKjxs3Jzc9G4ceO7nvOBBx6ots/Pzw/Xr1+XtrOystC9e/dq7YyP3rKystCuXTtkZWWhRYsW1Wpu2bLlXesgIgYiIpJBbXduzLmj07NnT3z66ac4d+4c9uzZg169ekEQBPTs2RN79uxBSEgIDAZDjXd37qR79+5o3rw5Jk2ahMzMzFoDlcFgAAC8+eabtXa4NncqAqVSWeN+8ZZO40RUPxiIiMjqMjIyTOYwOnPmDAwGgzQ3T1hYGAwGAzIyMkw6Hefk5CAvLw9hYWHSPmPQSU5OxuHDhzF9+nQAFZ2Yly9fjpCQEHh6eqJLly51rnPUqFF455130Lp1a3Ts2LHGNs2aNQMAuLq61jqho5G5j+zuJCwsDOnp6dX2nz59Wjpu/Pr7779DFEWT89b0XiKqjn2IiMjqli1bZrK9dOlSABVzGwHA4MGDAQCLFy82abdo0SIAwJAhQ6R94eHhaNy4MT744AOUlZWhR48eACqC0tmzZ/Htt9/ioYcegotL3f+99+KLL2LWrFl4//33a20TFBSEvn374t///jcuXbpU7fjly5el7z09PQEAeXl5da7FaPDgwTh06BD2798v7SsqKsKKFSvQtGlTtGnTRmp38eJFfPvtt1K7GzduYMWKFfd8biJnwjtERGSWzZs3S3clbvXwww9Ld01qk5mZiccffxwDBw7E/v378d///hejR49Ghw4dAAAdOnTA2LFjsWLFCuTl5aFPnz44dOgQVq1ahSeeeAIxMTEmn9erVy989dVXiIqKgp+fHwCgc+fO8PT0xB9//FHn/kNGYWFhJmux1WbZsmXo2bMnoqKi8NJLL6FZs2bIycnB/v378eeff+LYsWMAgI4dO0KpVGL+/PnIz8+HWq3GI488gqCgILNrmj59OtauXYtBgwZh4sSJ8Pf3x6pVq5CZmYnvvvsOCkXFv2tfeuklfPTRR3j22Wdx9OhRNGrUCF9++SU8PDzu6WdB5HRkHuVGRDbuTsPuAYiff/651Ba1DLs/efKkOHz4cNHLy0v08/MTJ0yYIN68edPkPGVlZeLs2bPF8PBw0dXVVQwNDRUTEhJMhrYbLVu2TAQgvvrqqyb7+/fvLwIQt2/fbta1GYfdm3P9tw67F0VRPHv2rPjss8+KGo1GdHV1FRs3biw+9thj4rfffmvS7tNPPxWbNWsmKpVKk+HvtZ27T58+Yp8+faqda/jw4aKvr6/o5uYmduvWTdy4cWO192ZlZYmPP/646OHhIQYGBopvvPGGuGXLFg67JzKDIIrsvUdERETOjX2IiIiIyOkxEBEREZHTYyAiIiIip8dARERERE6PgYiIiIicHgMREREROT1OzGgGg8GAixcvwsvLyyJT8RMREZH1iaKIgoIChISESJOY1oaByAwXL15EaGio3GUQERHRPbhw4QKaNGlyxzYMRGbw8vICUPED9fb2lrkaIiIiModOp0NoaKj0d/xOGIjMYHxM5u3tzUBERERkZ8zp7sJO1UREROT0GIiIiIjI6TEQERERkdNjICIiIiKnx0BERERETo+BiIiIiJweAxERERE5PQYiIiIicnoMREREROT0GIiIiIjI6TEQERERkdNjICIiIiKnx0Aks/ybZTit1cldBhERkVNjIJJRurYAHWZvxf/9+wBEUZS7HCIiIqfFQCSjsAAPKISKu0S5BSVyl0NEROS0GIhk5OaqRNMATwDAHzkFMldDRETkvBiIZBYR3AAA8EdOocyVEBEROS8GIplFBnsBADJ4h4iIiEg2DEQyi6gMRHxkRkREJB8GIplFVj4yy8gp5EgzIiIimTAQyaxZYAO4KAQUlJRDqyuWuxwiIiKnxEAkM5WLAk0DjSPN2LGaiIhIDgxENsD42OwPLfsRERERyYGByAZEBLFjNRERkZwYiGyAcej9H7l8ZEZERCQHBiIbYHxkdiangCPNiIiIZMBAZAOaBnrCVSmgqFSPv/Juyl0OERGR02EgsgGuSgXCK0eaZXCkGRERUb1jILIRkZyxmoiISDYMRDaiKhDxDhEREVF9YyCyEdISHrm8Q0RERFTfGIhsRIS06n0hDAaONCMiIqpPsgailJQUDB06FCEhIRAEARs2bDA5LghCja+FCxdKbZo2bVrt+Lx580w+5/jx4+jVqxfc3NwQGhqKBQsW1Mfl1UmYvwdUSgVulunx53WONCMiIqpPsgaioqIidOjQAcuWLavx+KVLl0xen332GQRBwLBhw0zazZkzx6Td66+/Lh3T6XQYMGAAwsLCcPToUSxcuBCJiYlYsWKFVa+trlyUCjRraFzTjI/NiIiI6pOLnCcfNGgQBg0aVOtxjUZjsv3DDz8gJiYGzZo1M9nv5eVVra3R6tWrUVpais8++wwqlQpt27ZFamoqFi1ahPHjx9//RVhQZLAXTmsL8EduAfq3CZa7HCIiIqdhN32IcnJysGnTJowbN67asXnz5iEgIACdOnXCwoULUV5eLh3bv38/evfuDZVKJe2LjY1Feno6rl+/XuO5SkpKoNPpTF71QepYzZFmRERE9UrWO0R1sWrVKnh5eeHJJ5802T9x4kR07twZ/v7+2LdvHxISEnDp0iUsWrQIAKDVahEeHm7ynuDgYOmYn59ftXMlJSVh9uzZVrqS2kVwLiIiIiJZ2E0g+uyzzzBmzBi4ubmZ7I+Pj5e+b9++PVQqFV5++WUkJSVBrVbf07kSEhJMPlen0yE0NPTeCq+DlpWB6ExuIfQGEUqFYPVzEhERkZ0Eoj179iA9PR3r1q27a9vu3bujvLwc58+fR8uWLaHRaJCTk2PSxrhdW78jtVp9z2HqfoT6e0DtokBJuQEXrt1A08rlPIiIiMi67KIP0X/+8x906dIFHTp0uGvb1NRUKBQKBAUFAQCio6ORkpKCsrIyqU1ycjJatmxZ4+MyOSkVAloEVfQj4mMzIiKi+iNrICosLERqaipSU1MBAJmZmUhNTUV2drbURqfT4ZtvvsGLL75Y7f379+/H4sWLcezYMZw7dw6rV6/G5MmT8fTTT0thZ/To0VCpVBg3bhzS0tKwbt06fPjhhyaPxGwJ1zQjIiKqf7I+Mjty5AhiYmKkbWNIGTt2LFauXAkA+OqrryCKIkaNGlXt/Wq1Gl999RUSExNRUlKC8PBwTJ482STs+Pj4YOvWrYiLi0OXLl0QGBiImTNn2tyQe6OIYOMdIo40IyIiqi+CKIpcJ+IudDodfHx8kJ+fD29vb6uea9vJHLz4xRG00nhhy6TeVj0XERGRI6vL32+76EPkTIyPzM5dLkK53iBzNURERM6BgcjGNPFzh7urEqV6A7Ku3ZC7HCIiIqfAQGRjFApB6keUwY7VRERE9YKByAZFBBlHmrFjNRERUX1gILJBkcGci4iIiKg+MRDZIM5FREREVL8YiGyQsQ9R5pUilHGkGRERkdUxENmgxr7u8FQpUaYXcf5KkdzlEBEROTwGIhskCAJaBLNjNRERUX1hILJRkVzklYiIqN4wENkoY8fqjFwGIiIiImtjILJRkRo+MiMiIqovDEQ2yjgX0fkrRSgt50gzIiIia2IgslEabzd4qV1QbhCRyZFmREREVsVAZKMEoWpNs3R2rCYiIrIqBiIbJnWsZiAiIiKyKgYiGxbBJTyIiIjqBQORDTN2rM7gSDMiIiKrYiCyYcZHZuevFqG4TC9zNURERI6LgciGBXmp4ePuCoMInLvMkWZERETWwkBkwwRBqHpsxhmriYiIrIaByMaxYzUREZH1MRDZOOMir+ladqwmIiKyFgYiG8dFXomIiKyPgcjGGR+ZZV+7gZulHGlGRERkDQxENi6wgQp+Hq4QReDsZT42IyIisgYGIhtXsaYZO1YTERFZEwORHTAOvf+DM1YTERFZBQORHWjJRV6JiIisioHIDkiPzDjSjIiIyCoYiOyAcej9hWs3caO0XOZqiIiIHA8DkR3w91QhsIEKAMCV74mIiCyPgchORARxpBkREZG1yBqIUlJSMHToUISEhEAQBGzYsMHk+HPPPQdBEExeAwcONGlz7do1jBkzBt7e3vD19cW4ceNQWGh6F+X48ePo1asX3NzcEBoaigULFlj70iyuapFX3iEiIiKyNFkDUVFRETp06IBly5bV2mbgwIG4dOmS9Fq7dq3J8TFjxiAtLQ3JycnYuHEjUlJSMH78eOm4TqfDgAEDEBYWhqNHj2LhwoVITEzEihUrrHZd1sC5iIiIiKzHRc6TDxo0CIMGDbpjG7VaDY1GU+OxU6dOYcuWLTh8+DC6du0KAFi6dCkGDx6Mf/3rXwgJCcHq1atRWlqKzz77DCqVCm3btkVqaioWLVpkEpxsnbSmGfsQERERWZzN9yHatWsXgoKC0LJlS7z66qu4evWqdGz//v3w9fWVwhAA9O/fHwqFAgcPHpTa9O7dGyqVSmoTGxuL9PR0XL9+vf4u5D4ZH5n9lXcThSUcaUZERGRJNh2IBg4ciC+++ALbt2/H/PnzsXv3bgwaNAh6fcUip1qtFkFBQSbvcXFxgb+/P7RardQmODjYpI1x29jmdiUlJdDpdCYvufl6qBDkpQbACRqJiIgsTdZHZnczcuRI6fuoqCi0b98ezZs3x65du9CvXz+rnTcpKQmzZ8+22uffq8hgL+QWlCAjpxCdHvCTuxwiIiKHYdN3iG7XrFkzBAYG4syZMwAAjUaD3Nxckzbl5eW4du2a1O9Io9EgJyfHpI1xu7a+SQkJCcjPz5deFy5csPSl3JOIysdm6bxDREREZFF2FYj+/PNPXL16FY0aNQIAREdHIy8vD0ePHpXa7NixAwaDAd27d5fapKSkoKysTGqTnJyMli1bws+v5rssarUa3t7eJi9bEMmRZkRERFYhayAqLCxEamoqUlNTAQCZmZlITU1FdnY2CgsLMXXqVBw4cADnz5/H9u3b8be//Q0tWrRAbGwsAKB169YYOHAgXnrpJRw6dAh79+7FhAkTMHLkSISEhAAARo8eDZVKhXHjxiEtLQ3r1q3Dhx9+iPj4eLku+55JcxFxpBkREZFFyRqIjhw5gk6dOqFTp04AgPj4eHTq1AkzZ86EUqnE8ePH8fjjjyMyMhLjxo1Dly5dsGfPHqjVaukzVq9ejVatWqFfv34YPHgwevbsaTLHkI+PD7Zu3YrMzEx06dIFU6ZMwcyZM+1qyL1Ri8rZqrW6YuTfLLtLayIiIjKXIIqiKHcRtk6n08HHxwf5+fmyPz576L3t0OqK8d2r0egS5i9rLURERLasLn+/7aoPEVV1rP6Dj82IiIgshoHIzrRkx2oiIiKLYyCyM1zCg4iIyPIYiOxM1SMz3iEiIiKyFAYiO2Nc9T63oAR5N0plroaIiMgxMBDZmQZqFzT2dQfAjtVERESWwkBkh/jYjIiIyLIYiOxQVcdqBiIiIiJLYCCyQxFBnIuIiIjIkhiI7FBLTeUdolzeISIiIrIEBiI71KLyDtGVwlJcK+JIMyIiovvFQGSHPFQuCPU3jjTjXSIiIqL7xUBkpyKDuIQHERGRpTAQ2akIrmlGRERkMQxEdiqSq94TERFZDAORnbp1LiJRFGWuhoiIyL4xENmp5g0bQBCA6zfKcKWQI82IiIjuBwORnXJXKfGAvwcAzlhNRER0vxiI7FgkO1YTERFZBAORHZM6VueyYzUREdH9YCCyY1zklYiIyDIYiOxYROXkjOlajjQjIiK6HwxEdqxZQ08oBEBXXI7cghK5yyEiIrJbDER2zM1ViaYBngDYsZqIiOh+MBDZuQjOWE1ERHTfGIjsHDtWExER3T8GIjvHuYiIiIjuHwORnau6Q1TIkWZERET3iIHIzoUHesJFIaCgpBxaXbHc5RAREdklBiI7p3JRoGmgcaQZO1YTERHdCwYiByAt4aFlPyIiIqJ7wUDkAIwzVrNjNRER0b1hIHIA0kgzLvJKRER0TxiIHIDxkdmZHK5pRkREdC9kDUQpKSkYOnQoQkJCIAgCNmzYIB0rKyvDtGnTEBUVBU9PT4SEhODZZ5/FxYsXTT6jadOmEATB5DVv3jyTNsePH0evXr3g5uaG0NBQLFiwoD4ur940DfSEq1JAUakef+XdlLscIiIiuyNrICoqKkKHDh2wbNmyasdu3LiB3377DTNmzMBvv/2G77//Hunp6Xj88certZ0zZw4uXbokvV5//XXpmE6nw4ABAxAWFoajR49i4cKFSExMxIoVK6x6bfXJValAs8CKu0QZHGlGRERUZy5ynnzQoEEYNGhQjcd8fHyQnJxssu+jjz5Ct27dkJ2djQceeEDa7+XlBY1GU+PnrF69GqWlpfjss8+gUqnQtm1bpKamYtGiRRg/frzlLkZmEcENkJ5TgD9yChDTKkjucoiIiOyKXfUhys/PhyAI8PX1Ndk/b948BAQEoFOnTli4cCHKy8ulY/v370fv3r2hUqmkfbGxsUhPT8f169frq3Srq1rCg3eIiIiI6krWO0R1UVxcjGnTpmHUqFHw9vaW9k+cOBGdO3eGv78/9u3bh4SEBFy6dAmLFi0CAGi1WoSHh5t8VnBwsHTMz8+v2rlKSkpQUlIibet0OmtckkVJcxFx6D0REVGd2UUgKisrw4gRIyCKIpYvX25yLD4+Xvq+ffv2UKlUePnll5GUlAS1Wn1P50tKSsLs2bPvq+b6FlF5h+hMbiEMBhEKhSBzRURERPbD5h+ZGcNQVlYWkpOTTe4O1aR79+4oLy/H+fPnAQAajQY5OTkmbYzbtfU7SkhIQH5+vvS6cOHC/V+IlYX5e0ClVOBmmR5/XudIMyIiorqw6UBkDEMZGRnYtm0bAgIC7vqe1NRUKBQKBAVVdCyOjo5GSkoKysrKpDbJyclo2bJljY/LAECtVsPb29vkZetclAo0a2hc04yPzYiIiOpC1kBUWFiI1NRUpKamAgAyMzORmpqK7OxslJWVYfjw4Thy5AhWr14NvV4PrVYLrVaL0tJSABUdphcvXoxjx47h3LlzWL16NSZPnoynn35aCjujR4+GSqXCuHHjkJaWhnXr1uHDDz80edTmKKpmrGYgIiIiqgtZ+xAdOXIEMTEx0rYxpIwdOxaJiYn48ccfAQAdO3Y0ed/OnTvRt29fqNVqfPXVV0hMTERJSQnCw8MxefJkk7Dj4+ODrVu3Ii4uDl26dEFgYCBmzpzpUEPujVpqvIBjnIuIiIiormQNRH379r3jUhN3W4aic+fOOHDgwF3P0759e+zZs6fO9dmbiCCONCMiIroXNt2HiOom8paRZnoD1zQjIiIyFwORAwn194DaRYGScgMuXLshdzlERER2g4HIgSgVAlpUPjZL52MzIiIiszEQORjjY7MMBiIiIiKzMRA5mAhpCQ+ONCMiIjIXA5GDiQwyLvLKO0RERETmYiByMMZHZucuF6Fcb5C5GiIiIvvAQORgmvi5w91ViVK9AVkcaUZERGQWBiIHo1AIUj8idqwmIiIyDwORA4qQ+hGxYzUREZE5GIgcUGQw5yIiIiKqCwYiB8S5iIiIiOqGgcgBGfsQZV4pQhlHmhEREd0VA5EDauzrDk+VEmV6EeevFMldDhERkc1jIHJAgiCgRTA7VhMREZmLgchBtZSW8GA/IiIiorthIHJQUsfqXAYiIiKiu2EgclARfGRGRERkNgYiB2Wci+j8lSKUlOtlroaIiMi2MRA5KI23G7zULig3iMjkSDMiIqI7YiByUIJQtaYZH5sRERHdGQORA+OM1UREROZhIHJgVR2rGYiIiIjuhIHIgRk7VmfwkRkREdEdMRA5sJaVd4jOXy1CcRlHmhEREdWGgciBNfRSw8fdFQYROHeZI82IiIhqw0DkwARBqHpsxhmriYiIasVA5OCMHavTtQxEREREtWEgcnCRQZyLiIiI6G4YiBwcF3klIiK6OwYiB2d8ZJZ97QZulnKkGRERUU0YiBxcYAMV/DxcIYrA2ct8bEZERFST+w5EWVlZOHnyJAwGgyXqIQurGGnGGauJiIjuxOxA9Nlnn2HRokUm+8aPH49mzZohKioK7dq1w4ULFyxeIN2/qkDEO0REREQ1MTsQrVixAn5+ftL2li1b8Pnnn+OLL77A4cOH4evri9mzZ9fp5CkpKRg6dChCQkIgCAI2bNhgclwURcycORONGjWCu7s7+vfvj4yMDJM2165dw5gxY+Dt7Q1fX1+MGzcOhYWmf/iPHz+OXr16wc3NDaGhoViwYEGd6rR3VUt48A4RERFRTcwORBkZGejatau0/cMPP+Bvf/sbxowZg86dO+O9997D9u3b63TyoqIidOjQAcuWLavx+IIFC7BkyRJ88sknOHjwIDw9PREbG4vi4mKpzZgxY5CWlobk5GRs3LgRKSkpGD9+vHRcp9NhwIABCAsLw9GjR7Fw4UIkJiZixYoVdarVnkmLvHKkGRERUc1EM7m7u4vnz5+Xttu3by9++OGH0nZWVpbo5uZm7sdVA0Bcv369tG0wGESNRiMuXLhQ2peXlyeq1Wpx7dq1oiiK4smTJ0UA4uHDh6U2mzdvFgVBEP/66y9RFEXx448/Fv38/MSSkhKpzbRp08SWLVuaXVt+fr4IQMzPz7/Xy5PV1cISMWzaRjFs2kaxsLhM7nKIiIjqRV3+fpt9h8h4hwUArly5grS0NPTo0UM6rtVq4ePjY7GglpmZCa1Wi/79+0v7fHx80L17d+zfvx8AsH//fvj6+prcuerfvz8UCgUOHjwotenduzdUKpXUJjY2Funp6bh+/XqN5y4pKYFOpzN52TN/TxUCG1Rc/5lc9iMiIiK6ndmBaOzYsYiLi8PcuXPx1FNPoVWrVujSpYt0fN++fWjXrp3FCtNqtQCA4OBgk/3BwcHSMa1Wi6CgIJPjLi4u8Pf3N2lT02fceo7bJSUlwcfHR3qFhobe/wXJLCKII82IiIhqY3Yg+sc//oGXXnoJ33//Pdzc3PDNN9+YHN+7dy9GjRpl8QLlkJCQgPz8fOnlCKPnqhZ55R0iIiKi27mY21ChUGDOnDmYM2dOjcdvD0j3S6PRAABycnLQqFEjaX9OTg46duwotcnNzTV5X3l5Oa5duya9X6PRICcnx6SNcdvY5nZqtRpqtdoi12ErIjgXERERUa3ua2LG4uJirFq1Ch9//DHOnDljqZoAAOHh4dBoNCYj13Q6HQ4ePIjo6GgAQHR0NPLy8qS+TQCwY8cOGAwGdO/eXWqTkpKCsrIyqU1ycjJatmxpMo2Ao2upqVzTjHMRERERVWN2IIqPj8frr78ubZeWliI6OhovvfQS3nrrLXTs2FHq7GyuwsJCpKamIjU1FUBFR+rU1FRkZ2dDEARMmjQJ77zzDn788UecOHECzz77LEJCQvDEE08AAFq3bo2BAwfipZdewqFDh7B3715MmDABI0eOREhICABg9OjRUKlUGDduHNLS0rBu3Tp8+OGHiI+Pr1Ot9i6ysg/RX3k3UVhSLnM1RERENsbcoWtt27YVf/jhB2n7s88+E/38/MTz58+LBoNBfO6558TBgwfXaTjczp07RQDVXmPHjhVFsWLo/YwZM8Tg4GBRrVaL/fr1E9PT000+4+rVq+KoUaPEBg0aiN7e3uLzzz8vFhQUmLQ5duyY2LNnT1GtVouNGzcW582bV6c67X3YvdGD7ySLYdM2ir9lXZO7FCIiIqury99vQRRF0Zzg5O3tjd9++w0tWrQAAIwaNQpeXl7SBIepqakYPHgwLl68aIXYJi+dTgcfHx/k5+fD29tb7nLu2dP/7yB+PXMF84dF4f8efEDucoiIiKyqLn+/zX5kplAocGt2OnDgAB566CFp29fXt9Z5fcg2RFSONOOaZkRERKbMDkStW7fGTz/9BABIS0tDdnY2YmJipONZWVnV5vsh28JV74mIiGpm9rD7f/zjHxg5ciQ2bdqEtLQ0DB48GOHh4dLxn3/+Gd26dbNKkWQZVYu88g4RERHRrcy+Q/T3v/8dP//8M9q3b4/Jkydj3bp1Jsc9PDzw2muvWbxAspwWlSPNtLpi5N8su0trIiIi52F2p2pn5iidqgEgOmk7LuUX47tXo9ElzF/ucoiIiKzGKp2qMzIyMGrUqBoXOs3Pz8fo0aNx7ty5uldL9apqxmo+NiMiIjIyOxAtXLgQoaGhNSYs4wKoCxcutGhxZHmRQcaRZuxYTUREZGR2INq9ezeeeuqpWo+PGDECO3bssEhRZD3GkWbsWE1ERFTF7ECUnZ2NoKCgWo8HBgY6xKrwjs44F1E67xARERFJzA5EPj4+OHv2bK3Hz5w5Y/cdjp2BsQ/R5YIS5N0olbkaIiIi22B2IOrduzeWLl1a6/ElS5agV69eFimKrKeB2gWNfd0BsGM1ERGRkdmBKCEhAZs3b8bw4cNx6NAh5OfnIz8/HwcPHsSwYcPwyy+/ICEhwZq1koVULeHBx2ZERERAHWaq7tSpE7799lu88MILWL9+vcmxgIAAfP311+jcubPFCyTLiwz2wq70y8hgICIiIgJQh0CUmZmJxx57DFlZWfjll1+QkZEBURQRGRmJAQMGwMPDw5p1kgVFci4iIiIiE2YHoubNmyMsLAwxMTGIiYnBqFGj0KRJE2vWRlYirWmWyztEREREQB0C0Y4dO7Br1y7s2rULa9euRWlpKZo1a4ZHHnlECklc7d4+tKicnPFKYSmuFZXC31Mlc0VERETyMjsQ9e3bF3379gUAFBcXY9++fVJAWrVqFcrKytCqVSukpaVZq1ayEA+VC0L93XHh2k38kVOAh5oFyF0SERGRrMwORLdyc3PDI488gp49eyImJgabN2/Gv//9b5w+fdrS9ZGVRAZ5MRARERFVMnvYPQCUlpYiJSUFs2fPRkxMDHx9ffHKK6/g+vXr+Oijj5CZmWmtOsnCqhZ5ZT8iIiIis+8QPfLIIzh48CDCw8PRp08fvPzyy1izZg0aNWpkzfrISiKluYg40oyIiMjsQLRnzx40atQIjzzyCPr27Ys+ffogIICPWuxV1SKvBRBFEYIgyFwRERGRfMx+ZJaXl4cVK1bAw8MD8+fPR0hICKKiojBhwgR8++23uHz5sjXrJAtrEdQAggBcv1GGK4Vc04yIiJyb2YHI09MTAwcOxLx583Dw4EFcuXIFCxYsgIeHBxYsWIAmTZqgXbt21qyVLMjNVYkw/4rJNDljNRERObs6daq+laenJ/z9/eHv7w8/Pz+4uLjg1KlTlqyNrIwdq4mIiCqY3YfIYDDgyJEj2LVrF3bu3Im9e/eiqKgIjRs3RkxMDJYtW4aYmBhr1koWFhncAMknc/BHLjtWExGRczM7EPn6+qKoqAgajQYxMTH44IMP0LdvXzRv3tya9ZEVSWuaaXmHiIiInJvZgWjhwoWIiYlBZGSkNeuhehQRVPXIjCPNiIjImZkdiF5++WVr1kEyaNbQEwoB0BWXI7egBMHebnKXREREJIt77lRN9s/NVYmmAZ4A2LGaiIicGwORk4vgjNVEREQMRM6u5S0zVhMRETkrBiInx7mIiIiIGIicXtWaZoUQRVHmaoiIiOTBQOTkwgM94aIQUFBSDq2uWO5yiIiIZGHzgahp06YQBKHaKy4uDgDQt2/fasdeeeUVk8/Izs7GkCFD4OHhgaCgIEydOhXl5eVyXI7NUbko0DSwYqRZOidoJCIiJ2X2PERyOXz4MPR6vbT9+++/49FHH8VTTz0l7XvppZcwZ84cadvDw0P6Xq/XY8iQIdBoNNi3bx8uXbqEZ599Fq6urnjvvffq5yJsXGRwA5zJLURGTiH6tgySuxwiIqJ6Z/OBqGHDhibb8+bNQ/PmzdGnTx9pn4eHBzQaTY3v37p1K06ePIlt27YhODgYHTt2xNy5czFt2jQkJiZCpVJZtX57UDFjtZYdq4mIyGnZ/COzW5WWluK///0vXnjhBZNlJlavXo3AwEC0a9cOCQkJuHHjhnRs//79iIqKQnBwsLQvNjYWOp0OaWlpNZ6npKQEOp3O5OXIpDXNuMgrERE5KZu/Q3SrDRs2IC8vD88995y0b/To0QgLC0NISAiOHz+OadOmIT09Hd9//z0AQKvVmoQhANK2Vqut8TxJSUmYPXu2dS7CBrXUVEzOeIZrmhERkZOyq0D0n//8B4MGDUJISIi0b/z48dL3UVFRaNSoEfr164ezZ8+iefPm93SehIQExMfHS9s6nQ6hoaH3XriNCwvwhKtSQFGpHn/l3UQTP4+7v4mIiMiB2M0js6ysLGzbtg0vvvjiHdt1794dAHDmzBkAgEajQU5Ojkkb43Zt/Y7UajW8vb1NXo7MValAs8CKu0QZXMKDiIickN0Eos8//xxBQUEYMmTIHdulpqYCABo1agQAiI6OxokTJ5Cbmyu1SU5Ohre3N9q0aWO1eu1N1Zpm7FhNRETOxy4emRkMBnz++ecYO3YsXFyqSj579izWrFmDwYMHIyAgAMePH8fkyZPRu3dvtG/fHgAwYMAAtGnTBs888wwWLFgArVaLt99+G3FxcVCr1XJdks2p6Fh9CekMRERE5ITsIhBt27YN2dnZeOGFF0z2q1QqbNu2DYsXL0ZRURFCQ0MxbNgwvP3221IbpVKJjRs34tVXX0V0dDQ8PT0xduxYk3mLqGIuIoCPzIiIyDkJIhewuiudTgcfHx/k5+c7bH+is5cL0e/93XB3VSJtdiwUCo40IyIi+1aXv99204eIrCvM3wMqpQI3y/T48/pNucshIiKqVwxEBABwUSrQrGHFmmbsWE1ERM6GgYgkLTXGGasZiIiIyLkwEJHEuIQHO1YTEZGzYSAiSUQQ5yIiIiLnxEBEEuMdojO5hdAbOPiQiIicBwMRSUL9PaB2UaCk3IDsazfkLoeIiKjeMBCRRKkQ0IKPzYiIyAkxEJGJqo7VDEREROQ8GIjIRNUirxxpRkREzoOBiEy0rLxDxEdmRETkTBiIyITxkdm5y0Uo1xtkroaIiKh+MBCRica+7nB3VaJUb0AWR5oREZGTYCAiEwqFIPUjYsdqIiJyFgxEVE1EUMVjs3QtO1YTEZFzYCCiaiKNI824yCsRETkJBiKqhnMRERGRs2EgomqMfYgyrxShjCPNiIjICTAQUTWNfd3hqVKiTC/i/JUiucshIiKyOgYiqkYQBERIEzSyYzURETk+BiKqkdSxmv2IiIjICTAQUY2kjtUcaUZERE6AgYhqxEdmRETkTBiIqEaRt4w0KynXy1wNERGRdTEQUY003m7wUrtAbxCRyZFmRETk4BiIqEYVI82MHav52IyIiBwbAxHVijNWExGRs2AgolpFSh2rGYiIiMixMRBRraruEPGRGREROTYGIqqVcaTZ+atFKC7jSDMiInJcDERUq4Zeavi4u8IgAucuc6QZERE5LgYiqpUgCFzCg4iInAIDEd1RBDtWExGRE2AgojuKDOJcRERE5PhsOhAlJiZCEASTV6tWraTjxcXFiIuLQ0BAABo0aIBhw4YhJyfH5DOys7MxZMgQeHh4ICgoCFOnTkV5eXl9X4rd4iKvRETkDFzkLuBu2rZti23btknbLi5VJU+ePBmbNm3CN998Ax8fH0yYMAFPPvkk9u7dCwDQ6/UYMmQINBoN9u3bh0uXLuHZZ5+Fq6sr3nvvvXq/FntkfGSWfe0Gbpbq4a5SylwRERGR5dn0HSKgIgBpNBrpFRgYCADIz8/Hf/7zHyxatAiPPPIIunTpgs8//xz79u3DgQMHAABbt27FyZMn8d///hcdO3bEoEGDMHfuXCxbtgylpaVyXpbdCGyggr+nCqIInL3Mx2ZEROSYbD4QZWRkICQkBM2aNcOYMWOQnZ0NADh69CjKysrQv39/qW2rVq3wwAMPYP/+/QCA/fv3IyoqCsHBwVKb2NhY6HQ6pKWl1XrOkpIS6HQ6k5ezEgQBEUEcaUZERI7NpgNR9+7dsXLlSmzZsgXLly9HZmYmevXqhYKCAmi1WqhUKvj6+pq8Jzg4GFqtFgCg1WpNwpDxuPFYbZKSkuDj4yO9QkNDLXthdqZqCQ/eISIiIsdk032IBg0aJH3fvn17dO/eHWFhYfj666/h7u5utfMmJCQgPj5e2tbpdE4dioxzEXGRVyIiclQ2fYfodr6+voiMjMSZM2eg0WhQWlqKvLw8kzY5OTnQaDQAAI1GU23UmXHb2KYmarUa3t7eJi9nZuxYnc5AREREDsquAlFhYSHOnj2LRo0aoUuXLnB1dcX27dul4+np6cjOzkZ0dDQAIDo6GidOnEBubq7UJjk5Gd7e3mjTpk2912+vjI/M/rx+E0UlnLKAiIgcj00HojfffBO7d+/G+fPnsW/fPvz973+HUqnEqFGj4OPjg3HjxiE+Ph47d+7E0aNH8fzzzyM6OhoPPfQQAGDAgAFo06YNnnnmGRw7dgy//PIL3n77bcTFxUGtVst8dfbD31OFwAYqAMCZXPYjIiIix2PTfYj+/PNPjBo1ClevXkXDhg3Rs2dPHDhwAA0bNgQAfPDBB1AoFBg2bBhKSkoQGxuLjz/+WHq/UqnExo0b8eqrryI6Ohqenp4YO3Ys5syZI9cl2a2IIC9cKbyKP3IK0CHUV+5yiIiILEoQRVGUuwhbp9Pp4OPjg/z8fKftT5T4YxpW7juP8b2b4a3BreUuh4iI6K7q8vfbph+Zke2I4Kr3RETkwBiIyCzSmmaci4iIiBwQAxGZJTKoIhD9lXcThRxpRkREDoaBiMzi4+GKIK+KkXmcoJGIiBwNAxGZrWoJDwYiIiJyLAxEZLaqjtXsR0RERI6FgYjMxjtERETkqBiIyGwcaUZERI6KgYjMZnxkptUVI/9mmczVEBERWQ4DEZnN280VjXzcAABncvnYjIiIHAcDEdVJhNSPiI/NiIjIcTAQUZ1EBnEJDyIicjwMRFQnHGlGRESOiIGI6oRzERERkSNiIKI6MfYhulxQgrwbpTJXQ0REZBkMRFQnDdQuaOzrDoB3iYiIyHEwEFGdRQazYzURETkWBiKqs6oZqxmIiIjIMTAQUZ1xLiIiInI0DERUZ8ZHZhmcrZqIiBwEAxHVWYvKyRmvFJbiamGJzNUQERHdPwYiqjMPlQtC/TnSjIiIHAcDEd2TyKDKjtV8bEZERA6AgYjuSQSX8CAiIgfCQET3pKWGS3gQEZHjYCCiexIRVDUXkSiKMldDRER0fxiI6J60CGoAhQBcv1GGK4Vc04yIiOwbAxHdEzdXJR7w9wDAGauJiMj+MRDRPWPHaiIichQMRHTPjDNWp7NjNRER2TkGIrpnXOSViIgcBQMR3TPjSLM/ONKMiIjsHAMR3bNmDT2hEABdcTlyC7imGRER2S8GIrpnbq5KNA30BMCO1UREZN9sOhAlJSXhwQcfhJeXF4KCgvDEE08gPT3dpE3fvn0hCILJ65VXXjFpk52djSFDhsDDwwNBQUGYOnUqysvL6/NSHFak9NiMHauJiMh+2XQg2r17N+Li4nDgwAEkJyejrKwMAwYMQFFRkUm7l156CZcuXZJeCxYskI7p9XoMGTIEpaWl2LdvH1atWoWVK1di5syZ9X05Dsk40owdq4mIyJ65yF3AnWzZssVke+XKlQgKCsLRo0fRu3dvab+Hhwc0Gk2Nn7F161acPHkS27ZtQ3BwMDp27Ii5c+di2rRpSExMhEqlsuo1ODrORURERI7Apu8Q3S4/Px8A4O/vb7J/9erVCAwMRLt27ZCQkIAbN25Ix/bv34+oqCgEBwdL+2JjY6HT6ZCWllbjeUpKSqDT6UxeVLOqofeFHGlGRER2y6bvEN3KYDBg0qRJ6NGjB9q1ayftHz16NMLCwhASEoLjx49j2rRpSE9Px/fffw8A0Gq1JmEIgLSt1WprPFdSUhJmz55tpStxLOGBnnBRCCgoKcel/GKE+LrLXRIREVGd2U0giouLw++//45ff/3VZP/48eOl76OiotCoUSP069cPZ8+eRfPmze/pXAkJCYiPj5e2dTodQkND761wB6dyUaBpoCfO5Bbij5wCBiIiIrJLdvHIbMKECdi4cSN27tyJJk2a3LFt9+7dAQBnzpwBAGg0GuTk5Ji0MW7X1u9IrVbD29vb5EW1q+pYzZFmRERkn2w6EImiiAkTJmD9+vXYsWMHwsPD7/qe1NRUAECjRo0AANHR0Thx4gRyc3OlNsnJyfD29kabNm2sUreziWTHaiIisnM2/cgsLi4Oa9aswQ8//AAvLy+pz4+Pjw/c3d1x9uxZrFmzBoMHD0ZAQACOHz+OyZMno3fv3mjfvj0AYMCAAWjTpg2eeeYZLFiwAFqtFm+//Tbi4uKgVqvlvDyHIQWiXN4hIiIi+2TTd4iWL1+O/Px89O3bF40aNZJe69atAwCoVCps27YNAwYMQKtWrTBlyhQMGzYMP/30k/QZSqUSGzduhFKpRHR0NJ5++mk8++yzmDNnjlyX5XCMj8zO5BSgoLhM5mqIiIjqThA5VvqudDodfHx8kJ+fz/5ENSjTG9D1nW3Iv1mGhl5qTB/YCn/v1BgKhSB3aURE5MTq8vfbpu8QkX1wVSrw72e6oGmABy4XlGDKN8cw/JN9OPFnvtylERERmYV3iMzAO0TmKSnX47Nfz2PpjgzcKNVDEICRD4bizQEtEdCA/bWIiKh+1eXvNwORGRiI6kabX4x5m09hQ+pFAICXmwviH43EMw+FwUXJm5JERFQ/GIgsjIHo3hw+fw2zfkjDyUsVS5+0DPbCrMfb4OHmgTJXRkREzoCByMIYiO6d3iBi7aFs/GtrOvJuVIxAGxLVCG8NaY3GnNWaiIisiIHIwhiI7l/ejVK8v/UPrD6YBYMIuLkq8FrfFhjfuxncXJVyl0dERA6IgcjCGIgs5+RFHRJ/SsOhzGsAgCZ+7pjxWBsMaBMMQeAwfSIishwGIgtjILIsURTx0/FLeG/TKWh1xQCAXhGBmDW0LVoENZC5OiIichQMRBbGQGQdRSXl+HjXGXyakolSvQEuCgHP92iKif0i4OXmKnd5RERk5xiILIyByLqyrhZh7saT2HaqYgHewAZqTBvYEsM6N+Fs10REdM8YiCyMgah+7EzPxdyfTuLclSIAQMdQX8x+vC06hPrKWxgREdklBiILYyCqP6XlBny2NxNLt2egqHK26xFdQjF1YEsEcrZrIiKqAwYiC2Mgqn85umLM33wa3//vLwAVs11P7h+JZ6LD4MrZromIyAwMRBbGQCSfI+evYdaPaUi7WDHbdWRwAyQObYuHW3C2ayIiujMGIgtjIJKX3iBi3eELWPjLaVyvnO16UDsN/jmkNZr4echcHRER2SoGIgtjILIN+TfKsCg5HV8eqJjtWu2iwKt9m+OVPs052zUREVXDQGRhDES25dQlHRJ/TMPBytmuG/u6Y8ZjrRHbVsPZromISMJAZGEMRLZHFEVsOnEJ7246hUv5FbNd92wRiFlD2yAi2Evm6oiIyBYwEFkYA5HtulFajo93nsWKlHPSbNdjH26KN/pHwJuzXRMROTUGIgtjILJ9WVeL8M6mU0g+mQMACGygwj8GtsJwznZNROS0GIgsjIHIfuxKz8WcW2a77lA523VHznZNROR0GIgsjIHIvpSWG7ByXyY+3FYx2zUAjOjaBFNjW6GhF2e7JiJyFgxEFsZAZJ9ydcWYt+U0vv+tcrZrtQve6B+BsQ835WzXREROgIHIwhiI7NvRrOtI/DENJ/7KBwC0CKqY7bpnBGe7JiJyZAxEFsZAZP/0BhHfHLmABb+k41pRKQBgYNuK2a5D/TnbNRGRI2IgsjAGIseRf6MMH2z7A18eyILeIELtosArfSpmu3ZXcbZrIiJHwkBkYQxEjue0tmK26wPnqma7fntIawxsx9muiYgcBQORhTEQOSZRFPHzCS3e3XQSFytnu+7RIgDxj0aisa8HfNxd4eaqYEAiIrJTDEQWxkDk2G6W6rF81xl8knIOpeUGk2OuSgHebq7wcXeFl3vFV283F3hL37vC293llu9N23A0GxGRfBiILIyByDlcuHYD8zafxr6zV6ArLofecP//aXiolFKg8nZ3ueX7yldt4crdFQ1ULpxlm4joPjAQWRgDkfMRRRE3SvXIv1kGXXEZdDfLK76v3K74vvyW4xX7CorLobtZhoKS8vuuQSEAXrffgbolXEnBqpbA5ebKTuJE5Nzq8vfbpZ5qIrIrgiDAU+0CT7ULQuBe5/eX6w0oLCk3CU01BSrT/VWhq6TcAIMI5FcGrQu4WecaXJUV1+DhqoSH2gWeKiU8VC7wVFd9dXc13fZQVbZTu8BDpYSHSglPlQs81BVf3V2VvGtFRA6JgYjIClyUCvh6qODrobqn9xeX6U3vTFXehTIGJ+MdqdrClUEEyvQi8m6UIQ9lFr02j8pgJQWmyvB0a3DyqCF8GcOWew3vUSnZeZ2I5MVARGSD3FyVcHNVIsir7u8VRRFFpXrobpbhRqkeN0rLUVRS+bVUj5u3bd8oqfxauf9mqR5FpeW4UapHUUnl19JyGB+uV3ym3qLX66IQqoLWLaHKU+0Cd5USahdF5avie1XltqraPqV0rMZ9rgqolUqoXRVQKRW820VEEqcKRMuWLcPChQuh1WrRoUMHLF26FN26dZO7LCKLEgQBDdQuaKC23H/eoiiiuMyAotJyKTBJoeo+wlZJ5ai+coNYceer+P77XtWFq1K4e4iqcZ/ytlCmgNpVCbVSIYUttWv1di4KAQpBgFJx2+u2fQpBgEvl97xzRlQ/nCYQrVu3DvHx8fjkk0/QvXt3LF68GLGxsUhPT0dQUJDc5RHZNEEQ4F75uMuSyvUG3CjT40aJvips3XJXyri/tNyA0nIDSsoNKCnXS9/fuq+khn2m7Sra3DqMpEwvokxfDpRY9LIsSiHAJCQpKoNSXcOVQlEVskw+SxCgVFZ8rWlfTZ9vbOOiNNYAkxCnuEsdNR2rfg7ARaG45bMVUChQ7RqrfV5lfUR15TSjzLp3744HH3wQH330EQDAYDAgNDQUr7/+OqZPn37H93KUGZFjEEUR5QbRNCSVGVCqN1R+rdguqSFU3fqeu4WzavvK9CjVG6A3VJzfYPwqitAbRFhghge6zZ3DF6TgpBAEKISK0CVUfr31+4r3VPyjQFHDcYXC+N5bj9+hvVBDe0VVe6V0rPK44i7vlc5lbGfaRoDxM257D6pfA1BV763XIAjVf0a3f616D0zrv/VzFaY1CzD9+bgoBTTyqfsgljvhKLPblJaW4ujRo0hISJD2KRQK9O/fH/v376/WvqSkBCUlVf9k1Ol09VInEVmXIAhwVQoVE2aq5a6milgZjPTGr7e+btlnMADlBgMMlcHu9n164/cGVL7PAL0BVV9v2WcMZXpRhF5vgF5EtaBWU3gzqUtf8dVQuW1sr69sX37r9/pbPkOESR21XbfhtvPc+rl3+6d8uUEEk6Z9CfJS49A/+8t2fqcIRFeuXIFer0dwcLDJ/uDgYJw+fbpa+6SkJMyePbu+yiMiJydUPn5yiv8hW4h4a2gTTcNhRZhCtTClN9weqiruzhm/GsSKY6L0PSq3Kz7PUEt7wy3Ha3yvePt7bz1eEQrr1P7WfQbTc4qovX4RNdVfsX3754q3XYtYQw3ibT8zEbd8hqHqPTWe11D9PWpXeWf2539/NUhISEB8fLy0rdPpEBoaKmNFRER0KylEcv5RshCnCESBgYFQKpXIyckx2Z+TkwONRlOtvVqthlptQ/fTiYiIyKqcYuVJlUqFLl26YPv27dI+g8GA7du3Izo6WsbKiIiIyBY4xR0iAIiPj8fYsWPRtWtXdOvWDYsXL0ZRURGef/55uUsjIiIimTlNIPq///s/XL58GTNnzoRWq0XHjh2xZcuWah2tiYiIyPk4zTxE94PzEBEREdmfuvz9doo+RERERER3wkBERERETo+BiIiIiJweAxERERE5PQYiIiIicnoMREREROT0GIiIiIjI6TEQERERkdNjICIiIiKn5zRLd9wP42TeOp1O5kqIiIjIXMa/2+YsysFAZIaCggIAQGhoqMyVEBERUV0VFBTAx8fnjm24lpkZDAYDLl68CC8vLwiCIHc5Nkmn0yE0NBQXLlzgem82gL8P28Lfh+3h78S2WOv3IYoiCgoKEBISAoXizr2EeIfIDAqFAk2aNJG7DLvg7e3N/7nYEP4+bAt/H7aHvxPbYo3fx93uDBmxUzURERE5PQYiIiIicnoMRGQRarUas2bNglqtlrsUAn8ftoa/D9vD34ltsYXfBztVExERkdPjHSIiIiJyegxERERE5PQYiIiIiMjpMRARERGR02MgovuSlJSEBx98EF5eXggKCsITTzyB9PR0ucuiSvPmzYMgCJg0aZLcpTitv/76C08//TQCAgLg7u6OqKgoHDlyRO6ynJJer8eMGTMQHh4Od3d3NG/eHHPnzjVrnSuyjJSUFAwdOhQhISEQBAEbNmwwOS6KImbOnIlGjRrB3d0d/fv3R0ZGRr3UxkBE92X37t2Ii4vDgQMHkJycjLKyMgwYMABFRUVyl+b0Dh8+jH//+99o37693KU4revXr6NHjx5wdXXF5s2bcfLkSbz//vvw8/OTuzSnNH/+fCxfvhwfffQRTp06hfnz52PBggVYunSp3KU5jaKiInTo0AHLli2r8fiCBQuwZMkSfPLJJzh48CA8PT0RGxuL4uJiq9fGYfdkUZcvX0ZQUBB2796N3r17y12O0yosLETnzp3x8ccf45133kHHjh2xePFiuctyOtOnT8fevXuxZ88euUshAI899hiCg4Pxn//8R9o3bNgwuLu747///a+MlTknQRCwfv16PPHEEwAq7g6FhIRgypQpePPNNwEA+fn5CA4OxsqVKzFy5Eir1sM7RGRR+fn5AAB/f3+ZK3FucXFxGDJkCPr37y93KU7txx9/RNeuXfHUU08hKCgInTp1wqeffip3WU7r4Ycfxvbt2/HHH38AAI4dO4Zff/0VgwYNkrkyAoDMzExotVqT/2/5+Pige/fu2L9/v9XPz8VdyWIMBgMmTZqEHj16oF27dnKX47S++uor/Pbbbzh8+LDcpTi9c+fOYfny5YiPj8dbb72Fw4cPY+LEiVCpVBg7dqzc5Tmd6dOnQ6fToVWrVlAqldDr9Xj33XcxZswYuUsjAFqtFgAQHBxssj84OFg6Zk0MRGQxcXFx+P333/Hrr7/KXYrTunDhAt544w0kJyfDzc1N7nKcnsFgQNeuXfHee+8BADp16oTff/8dn3zyCQORDL7++musXr0aa9asQdu2bZGamopJkyYhJCSEvw/iIzOyjAkTJmDjxo3YuXMnmjRpInc5Tuvo0aPIzc1F586d4eLiAhcXF+zevRtLliyBi4sL9Hq93CU6lUaNGqFNmzYm+1q3bo3s7GyZKnJuU6dOxfTp0zFy5EhERUXhmWeeweTJk5GUlCR3aQRAo9EAAHJyckz25+TkSMesiYGI7osoipgwYQLWr1+PHTt2IDw8XO6SnFq/fv1w4sQJpKamSq+uXbtizJgxSE1NhVKplLtEp9KjR49q01D88ccfCAsLk6ki53bjxg0oFKZ/9pRKJQwGg0wV0a3Cw8Oh0Wiwfft2aZ9Op8PBgwcRHR1t9fPzkRndl7i4OKxZswY//PADvLy8pOe8Pj4+cHd3l7k65+Pl5VWt/5anpycCAgLYr0sGkydPxsMPP4z33nsPI0aMwKFDh7BixQqsWLFC7tKc0tChQ/Huu+/igQceQNu2bfG///0PixYtwgsvvCB3aU6jsLAQZ86ckbYzMzORmpoKf39/PPDAA5g0aRLeeecdREREIDw8HDNmzEBISIg0Es2qRKL7AKDG1+effy53aVSpT58+4htvvCF3GU7rp59+Etu1ayeq1WqxVatW4ooVK+QuyWnpdDrxjTfeEB944AHRzc1NbNasmfjPf/5TLCkpkbs0p7Fz584a/2aMHTtWFEVRNBgM4owZM8Tg4GBRrVaL/fr1E9PT0+ulNs5DRERERE6PfYiIiIjI6TEQERERkdNjICIiIiKnx0BERERETo+BiIiIiJweAxERERE5PQYiIiIicnoMREQkm/Pnz0MQBKSmpspdiuT06dN46KGH4Obmho4dO97XZwmCgA0bNlikLiKyLgYiIif23HPPQRAEzJs3z2T/hg0bIAiCTFXJa9asWfD09ER6errJmkq302q1eP3119GsWTOo1WqEhoZi6NChd3zP/di1axcEQUBeXp5VPp/I2TEQETk5Nzc3zJ8/H9evX5e7FIspLS295/eePXsWPXv2RFhYGAICAmpsc/78eXTp0gU7duzAwoULceLECWzZsgUxMTGIi4u753PXB1EUUV5eLncZRDaHgYjIyfXv3x8ajQZJSUm1tklMTKz2+Gjx4sVo2rSptP3cc8/hiSeewHvvvYfg4GD4+vpizpw5KC8vx9SpU+Hv748mTZrg888/r/b5p0+fxsMPPww3Nze0a9cOu3fvNjn++++/Y9CgQWjQoAGCg4PxzDPP4MqVK9Lxvn37YsKECZg0aRICAwMRGxtb43UYDAbMmTMHTZo0gVqtRseOHbFlyxbpuCAIOHr0KObMmQNBEJCYmFjj57z22msQBAGHDh3CsGHDEBkZibZt2yI+Ph4HDhyo8T013eFJTU2FIAg4f/48ACArKwtDhw6Fn58fPD090bZtW/z88884f/48YmJiAAB+fn4QBAHPPfecdE1JSUkIDw+Hu7s7OnTogG+//bbaeTdv3owuXbpArVbj119/xbFjxxATEwMvLy94e3ujS5cuOHLkSI21EzkDBiIiJ6dUKvHee+9h6dKl+PPPP+/rs3bs2IGLFy8iJSUFixYtwqxZs/DYY4/Bz88PBw8exCuvvIKXX3652nmmTp2KKVOm4H//+x+io6MxdOhQXL16FQCQl5eHRx55BJ06dcKRI0ewZcsW5OTkYMSIESafsWrVKqhUKuzduxeffPJJjfV9+OGHeP/99/Gvf/0Lx48fR2xsLB5//HFkZGQAAC5duoS2bdtiypQpuHTpEt58881qn3Ht2jVs2bIFcXFx8PT0rHbc19f3Xn50AIC4uDiUlJQgJSUFJ06cwPz589GgQQOEhobiu+++AwCkp6fj0qVL+PDDDwEASUlJ+OKLL/DJJ58gLS0NkydPxtNPP10tVE6fPh3z5s3DqVOn0L59e4wZMwZNmjTB4cOHcfToUUyfPh2urq73XDuR3auXJWSJyCaNHTtW/Nvf/iaKoig+9NBD4gsvvCCKoiiuX79evPV/D7NmzRI7dOhg8t4PPvhADAsLM/mssLAwUa/XS/tatmwp9urVS9ouLy8XPT09xbVr14qiKIqZmZkiAHHevHlSm7KyMrFJkybi/PnzRVEUxblz54oDBgwwOfeFCxdEANIq2H369BE7dep01+sNCQkR3333XZN9Dz74oPjaa69J2x06dBBnzZpV62ccPHhQBCB+//33dz0fAHH9+vWiKFat8n39+nXp+P/+9z8RgJiZmSmKoihGRUWJiYmJNX5WTe8vLi4WPTw8xH379pm0HTdunDhq1CiT923YsMGkjZeXl7hy5cq7XgORs3CRLYkRkU2ZP38+HnnkkRrvipirbdu2UCiqbjwHBwejXbt20rZSqURAQAByc3NN3hcdHS197+Ligq5du+LUqVMAgGPHjmHnzp1o0KBBtfOdPXsWkZGRAIAuXbrcsTadToeLFy+iR48eJvt79OiBY8eOmXmFFX1wrGXixIl49dVXsXXrVvTv3x/Dhg1D+/bta21/5swZ3LhxA48++qjJ/tLSUnTq1MlkX9euXU224+Pj8eKLL+LLL79E//798dRTT6F58+aWuxgiO8NHZkQEAOjduzdiY2ORkJBQ7ZhCoagWBMrKyqq1u/2RiyAINe4zGAxm11VYWIihQ4ciNTXV5JWRkYHevXtL7Wp6fGUNEREREAQBp0+frtP7jEHx1p/j7T/DF198EefOncMzzzyDEydOoGvXrli6dGmtn1lYWAgA2LRpk8nP5uTJkyb9iIDqP5/ExESkpaVhyJAh2LFjB9q0aYP169fX6ZqIHAkDERFJ5s2bh59++gn79+832d+wYUNotVqTP+aWnDvo1o7I5eXlOHr0KFq3bg0A6Ny5M9LS0tC0aVO0aNHC5FWXEOTt7Y2QkBDs3bvXZP/evXvRpk0bsz/H398fsbGxWLZsGYqKiqodr21YfMOGDQFU9FMyqulnGBoaildeeQXff/89pkyZgk8//RQAoFKpAAB6vV5q26ZNG6jVamRnZ1f72YSGht71WiIjIzF58mRs3boVTz75ZI0d3omcBQMREUmioqIwZswYLFmyxGR/3759cfnyZSxYsABnz57FsmXLsHnzZoudd9myZVi/fj1Onz6NuLg4XL9+HS+88AKAio7G165dw6hRo3D48GGcPXsWv/zyC55//nmTcGCOqVOnYv78+Vi3bh3S09Mxffp0pKam4o033qhzvXq9Ht26dcN3332HjIwMnDp1CkuWLDF5/HcrY0hJTExERkYGNm3ahPfff9+kzaRJk/DLL78gMzMTv/32G3bu3CkFw7CwMAiCgI0bN+Ly5csoLCyEl5cX3nzzTUyePBmrVq3C2bNn8dtvv2Hp0qVYtWpVrfXfvHkTEyZMwK5du5CVlYW9e/fi8OHD0rmInBEDERGZmDNnTrVHWq1bt8bHH3+MZcuWoUOHDjh06NB99TW63bx58zBv3jx06NABv/76K3788UcEBgYCgHRXR6/XY8CAAYiKisKkSZPg6+tr0l/JHBMnTkR8fDymTJmCqKgobNmyBT/++CMiIiLq9DnNmjXDb7/9hpiYGEyZMgXt2rXDo48+iu3bt2P58uU1vsfV1RVr167F6dOn0b59e8yfPx/vvPOOSRu9Xo+4uDi0bt0aAwcORGRkJD7++GMAQOPGjTF79mxMnz4dwcHBmDBhAgBg7ty5mDFjBpKSkqT3bdq0CeHh4bXWr1QqcfXqVTz77LOIjIzEiBEjMGjQIMyePbtOPwciRyKI1uwhSERERGQHeIeIiIiInB4DERERETk9BiIiIiJyegxERERE5PQYiIiIiMjpMRARERGR02MgIiIiIqfHQEREREROj4GIiIiInB4DERERETk9BiIiIiJyegxERERE5PT+P7kUamAAI3UaAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2hZaL_Fk4ks",
        "outputId": "439d20aa-d3a6-4637-9b8d-ca1a1347f720"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([16.56060583, 16.56040907, 16.50930645, ..., 16.55409088,\n",
              "       16.56081669, 16.56126161])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer 6:"
      ],
      "metadata": {
        "id": "IEw5Ml2MnRsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from flask import Flask, request, jsonify\n",
        "\n",
        "# Load the Breast Cancer Wisconsin (Diagnostic) dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Preprocess the data\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the classification models\n",
        "logreg = LogisticRegression(random_state=42)\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "gb.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the models\n",
        "# ```python\n",
        "logreg_acc = accuracy_score(y_test, logreg.predict(X_test))\n",
        "dt_acc = accuracy_score(y_test, dt.predict(X_test))\n",
        "rf_acc = accuracy_score(y_test, rf.predict(X_test))\n",
        "gb_acc = accuracy_score(y_test, gb.predict(X_test))\n",
        "\n",
        "# Build a Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/', methods=['POST'])\n",
        "def predict_loan_eligibility():\n",
        "    data = request.get_json()\n",
        "    data = pd.DataFrame.from_dict(data)\n",
        "    data = scaler.transform(data)\n",
        "    prediction = {\n",
        "        'Logistic Regression': int(logreg.predict(data)[0]),\n",
        "        'Decision Tree': int(dt.predict(data)[0]),\n",
        "        'Random Forest': int(rf.predict(data)[0]),\n",
        "        'Gradient Boosting': int(gb.predict(data)[0])\n",
        "    }\n",
        "    return jsonify(prediction)\n",
        "\n",
        "# Build a Docker image\n",
        "FROM python:3.9\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "RUN pip install -r requirements.txt\n",
        "COPY app.py .\n",
        "CMD [ \"python\", \"app.py\" ]\n",
        "\n",
        "# Run the Docker container\n",
        "docker build -t loan-eligibility-predictor .\n",
        "docker run -p 8000:8000 loan-eligibility-predictor"
      ],
      "metadata": {
        "id": "IwttzzufnUC_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_acc # decision_tree"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T47hbTnxn7H3",
        "outputId": "84353d32-2c11-43ed-fadb-008252f77d25"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9473684210526315"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_acc #random_forest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZrALHzgoyY8",
        "outputId": "94cd87ec-7728-4ff1-c2a6-bc5c56d606a6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9649122807017544"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gb_acc # gradient_boost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3JZx-Qr4DNC",
        "outputId": "9b889a97-631b-4e7d-a60a-e2503fb645ff"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.956140350877193"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer 7:"
      ],
      "metadata": {
        "id": "jDEaKTRRpXqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import adjusted_rand_score\n",
        "import plotly.graph_objects as go\n",
        "from flask import Flask, render_template\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/data.csv')\n",
        "\n",
        "# Prepare the data\n",
        "X = data.drop(['filename', 'label'], axis=1)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Choose an unsupervised clustering algorithm\n",
        "kmeans = KMeans(n_clusters=4, random_state=42)\n",
        "kmeans.fit(X)\n",
        "\n",
        "# Evaluate the accuracy of the unsupervised algorithm\n",
        "ari = adjusted_rand_score(data['label'], kmeans.labels_)\n",
        "print('Adjusted Rand Index (ARI):', ari)\n",
        "\n",
        "# Build a Flask application to display the accuracy in a frontend\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    # Create an elbow plot to determine the optimal number of clusters\n",
        "    inertia = []\n",
        "    for k in range(1, 11):\n",
        "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "        kmeans.fit(X)\n",
        "        inertia.append(kmeans.inertia_)\n",
        "\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=list(range(1, 11)), y=inertia, mode='lines'))\n",
        "    fig.update_layout(title='Elbow Method', xaxis_title='Number of Clusters', yaxis_title='Inertia')\n",
        "    fig.write_html('templates/elbow.html')\n",
        "\n",
        "    # Compute the ARI value\n",
        "    ari = adjusted_rand_score(data['label'], kmeans.labels_)\n",
        "\n",
        "    # Render the index.html template with the ARI value and elbow plot\n",
        "    return render_template('index.html', ari=ari)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n",
        "\n",
        "# In the index.html template, we can use simple HTML and Plotly to display the ARI value and the elbow plot\n",
        "# Here is an example of the index.html template:\n",
        "\n",
        "\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "  <head>\n",
        "    <title>Unsupervised Music Genre Prediction</title>\n",
        "  </head>\n",
        "  <body>\n",
        "    <h1>Unsupervised Music Genre Prediction</h1>\n",
        "    <h2>Adjusted Rand Index (ARI): {{ ari }}</h2>\n",
        "    <div id=\"plot\"></div>\n",
        "    <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
        "    <script>\n",
        "      Plotly.d3.csv('/static/elbow.csv', function(data) {\n",
        "        var x = [], y = [];\n",
        "        for (var i = 0; i < data.length; i++) {\n",
        "          x.push(data[i]['x']);\n",
        "          y.push(data[i]['y']);\n",
        "       }\n",
        "        var trace = {\n",
        "          x: x,\n",
        "          y: y,\n",
        "          type: 'scatter',\n",
        "          mode: 'lines',\n",
        "          name: 'Inertia'\n",
        "        };\n",
        "        var layout = {\n",
        "          title: 'Elbow Method',\n",
        "          xaxis: {\n",
        "            title: 'Number of Clusters'\n",
        "          },\n",
        "          yaxis: {\n",
        "            title: 'Inertia'\n",
        "          }\n",
        "        };\n",
        "        Plotly.newPlot('plot', [trace], layout);\n",
        "      });\n",
        "    </script>\n",
        "  </body>\n",
        "</html>\n",
        "\n",
        "# Adjusted Rand Index (ARI): 0.1531170089652427"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeOA_BnKpa37",
        "outputId": "ccba6e8f-1aca-47ee-98b0-35f19dbd9e96"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjusted Rand Index (ARI): 0.1531170089652427\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer 8"
      ],
      "metadata": {
        "id": "ONlCnyzUwUoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load and preprocess the data\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/train.csv\")\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Perform TF-IDF vectorization\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df[\"question1\"] + \" \" + df[\"question2\"])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "y = df[\"is_duplicate\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a supervised algorithm\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4EgRLlQsrZ0",
        "outputId": "325482e9-861c-43ed-aeca-c907f05dd724"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7547305152242202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0KppULS17cL",
        "outputId": "db543111-2ebe-450b-d872-25a7c1aa3984"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer 9: --->"
      ],
      "metadata": {
        "id": "S7z9RI_OiezL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UYSSxTDcmNrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advance ML\n",
        "\n"
      ],
      "metadata": {
        "id": "01McSDZdnh9s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer 1--->\n"
      ],
      "metadata": {
        "id": "a55FEtgPrNjb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MaLZ9N4Enj9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer 2\n",
        "A chemist had two chemical flasks labeled 0 and 1 which consist of two\n",
        "different chemicals. He extracted 3 features from these chemicals in order to\n",
        "distinguish between them, you provided the results derived by the chemicals and\n",
        "your task is to create a model that will label chemical 0 or 1 given its three features\n",
        "and built-in docker and use some library to display that in frontend.\n",
        "Note : Use only pyspark\n",
        "https://www.kaggle.com/datasets/uciml/indian-liver-patient-records\n",
        " This is the Dataset You can use this dataset for this question.\n"
      ],
      "metadata": {
        "id": "XikMUxkGnl2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyspark"
      ],
      "metadata": {
        "id": "XjBEkHOWsA5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "# Step 1: Load the dataset into a PySpark DataFrame\n",
        "spark = SparkSession.builder.appName('ChemicalClassification').getOrCreate()\n",
        "data = spark.read.csv('indian_liver_patient.csv', header=True, inferSchema=True)\n",
        "\n",
        "# Step 2: Perform some basic EDA\n",
        "data.printSchema()\n",
        "data.describe().show()\n",
        "data.groupBy('Dataset').count().show()\n",
        "\n",
        "# Step 3: Split the dataset into training and testing sets\n",
        "train_data, test_data = data.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "# Step 4: Define a pipeline to preprocess the data and train a classification model\n",
        "assembler = VectorAssembler(inputCols=['Age', 'Total_Bilirubin', 'Albumin'], outputCol='features')\n",
        "scaler = StandardScaler(inputCol='features', outputCol='scaled_features')\n",
        "lr = LogisticRegression(featuresCol='scaled_features', labelCol='Dataset')\n",
        "\n",
        "pipeline = Pipeline(stages=[assembler, scaler, lr])\n",
        "\n",
        "# Step 5: Fit the pipeline on the training data and evaluate the performance on the testing data\n",
        "model = pipeline.fit(train_data)\n",
        "predictions = model.transform(test_data)\n",
        "accuracy = predictions.filter(predictions.Dataset == predictions.prediction).count() / float(predictions.count())\n",
        "print('Accuracy:', accuracy)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from flask import Flask, request, jsonify\n",
        "import requests\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "model_url = 'http://<your-model-url>'\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return 'Welcome to the Chemical Classification Web App!'\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    age = request.form.get('age')\n",
        "    total_bilirubin = request.form.get('total_bilirubin')\n",
        "    albumin = request.form.get('albumin')\n",
        "\n",
        "    input_data = {'age': age, 'total_bilirubin': total_bilirubin, 'albumin': albumin}\n",
        "\n",
        "    response = requests.post(model_url, json=input_data)\n",
        "\n",
        "    if response.ok:\n",
        "        prediction = response.json()['prediction']\n",
        "        return jsonify({'prediction': prediction})\n",
        "    else:\n",
        "        return jsonify({'error': 'Failed to get prediction'})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_OhZreqnlKP",
        "outputId": "671be181-eaf6-49d0-96a4-5d9088f62f6a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Age: integer (nullable = true)\n",
            " |-- Gender: string (nullable = true)\n",
            " |-- Total_Bilirubin: double (nullable = true)\n",
            " |-- Direct_Bilirubin: double (nullable = true)\n",
            " |-- Alkaline_Phosphotase: integer (nullable = true)\n",
            " |-- Alamine_Aminotransferase: integer (nullable = true)\n",
            " |-- Aspartate_Aminotransferase: integer (nullable = true)\n",
            " |-- Total_Protiens: double (nullable = true)\n",
            " |-- Albumin: double (nullable = true)\n",
            " |-- Albumin_and_Globulin_Ratio: double (nullable = true)\n",
            " |-- Dataset: integer (nullable = true)\n",
            "\n",
            "+-------+------------------+------+-----------------+------------------+--------------------+------------------------+--------------------------+------------------+-----------------+--------------------------+------------------+\n",
            "|summary|               Age|Gender|  Total_Bilirubin|  Direct_Bilirubin|Alkaline_Phosphotase|Alamine_Aminotransferase|Aspartate_Aminotransferase|    Total_Protiens|          Albumin|Albumin_and_Globulin_Ratio|           Dataset|\n",
            "+-------+------------------+------+-----------------+------------------+--------------------+------------------------+--------------------------+------------------+-----------------+--------------------------+------------------+\n",
            "|  count|               583|   583|              583|               583|                 583|                     583|                       583|               583|              583|                       579|               583|\n",
            "|   mean| 44.74614065180103|  null|3.298799313893652|1.4861063464837074|  290.57632933104634|       80.71355060034305|        109.91080617495712| 6.483190394511151| 3.14185248713551|        0.9470639032815201|1.2864493996569468|\n",
            "| stddev|16.189833304694375|  null|6.209521726180151| 2.808497617658965|  242.93798917934402|       182.6203560342026|         288.9185290517341|1.0854514840234648|0.795518805964026|       0.31959210767237056|0.4524901515081166|\n",
            "|    min|                 4|Female|              0.4|               0.1|                  63|                      10|                        10|               2.7|              0.9|                       0.3|                 1|\n",
            "|    max|                90|  Male|             75.0|              19.7|                2110|                    2000|                      4929|               9.6|              5.5|                       2.8|                 2|\n",
            "+-------+------------------+------+-----------------+------------------+--------------------+------------------------+--------------------------+------------------+-----------------+--------------------------+------------------+\n",
            "\n",
            "+-------+-----+\n",
            "|Dataset|count|\n",
            "+-------+-----+\n",
            "|      1|  416|\n",
            "|      2|  167|\n",
            "+-------+-----+\n",
            "\n",
            "Accuracy: 0.7162162162162162\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer 3:\n",
        " A company wants to predict the sales of its product based on the money spent\n",
        "on different platforms for marketing. They want you to figure out how they can\n",
        "spend money on marketing in the future in such a way that they can increase their\n",
        "profit as much as possible built-in docker and use some library to display that in\n",
        "frontend https://www.kaggle.com/datasets/ashydv/advertising-dataset\n",
        " This is the Dataset You can use this dataset for this question. Note:\n",
        "Use only Dask\n"
      ],
      "metadata": {
        "id": "ULLKwpNUtPPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dask[dataframe]\n",
        "pip install dask_ml"
      ],
      "metadata": {
        "id": "qIjh2SDZxG7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "import dask.array as da\n",
        "from dask_ml.model_selection import train_test_split\n",
        "from dask_ml.linear_model import LinearRegression\n",
        "from dask_ml.metrics import mean_squared_error\n",
        "from dask_ml.preprocessing import StandardScaler\n",
        "\n",
        "# Load the advertising dataset\n",
        "df = dd.read_csv(\"advertising.csv\")\n",
        "\n",
        "# Assign column names to the dataframe\n",
        "df.columns = ['TV', 'Radio', 'Newspaper', 'Sales']\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X = df[['TV', 'Radio', 'Newspaper']].to_dask_array(lengths=True)\n",
        "y = df['Sales'].to_dask_array(lengths=True)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled= scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train a linear regression model\n",
        "model = LinearRegression(fit_intercept=True)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Compute the mean squared error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "\n",
        "# Optimize marketing budget for maximum profit\n",
        "budgets = [100, 200, 300, 400, 500]  # Specify the budget values to optimize\n",
        "profits = []\n",
        "\n",
        "for budget in budgets:\n",
        "    # Allocate the budget proportionally based on feature coefficients\n",
        "    budget_allocation = model.coef_ * budget\n",
        "\n",
        "    # Compute the predicted sales with the budget allocation\n",
        "    predicted_sales = model.predict(budget_allocation.reshape(1, -1))\n",
        "\n",
        "    # Compute the profit by subtracting the marketing budget from the predicted sales\n",
        "    profit = predicted_sales - budget\n",
        "\n",
        "    profits.append(profit)\n",
        "\n",
        "# Determine the optimal budget and maximum profit\n",
        "optimal_budget = budgets[profits.index(max(profits))]\n",
        "max_profit = max(profits)\n",
        "\n",
        "print(\"Optimal Budget:\", optimal_budget)\n",
        "print(\"Max Profit:\", max_profit)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ya61fST29rpO",
        "outputId": "4871d45e-7ee9-45c9-b539-7f09c6d7c41f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 2.852372223432255\n",
            "Optimal Budget: 500\n",
            "Max Profit: [12199.7300418]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code for Docker_file"
      ],
      "metadata": {
        "id": "S4RhsbVxGsFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use an official Python runtime as the base image\n",
        "FROM python:3.9\n",
        "\n",
        "# Set the working directory in the container\n",
        "WORKDIR /app\n",
        "\n",
        "# Copy the requirements file into the container\n",
        "COPY requirements.txt .\n",
        "\n",
        "# Install the Python dependencies\n",
        "RUN pip install --no-cache-dir -r requirements.txt\n",
        "\n",
        "# Copy the code into the container\n",
        "COPY . .\n",
        "\n",
        "# Expose a port if necessary\n",
        "# EXPOSE 8000\n",
        "\n",
        "# Run the command to start the application\n",
        "CMD [\"python\", \"app.py\"]\n"
      ],
      "metadata": {
        "id": "mTKG19T_Bkhd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "code for app.py"
      ],
      "metadata": {
        "id": "KjpO2DEjGyln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "from dask_ml.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from flask import Flask, request, jsonify\n",
        "\n",
        "# Load the advertising dataset\n",
        "df = dd.read_csv(\"advertising.csv\")\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X = df[['TV', 'Radio', 'Newspaper']].compute()\n",
        "y = df['Sales'].compute()\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train a linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Create a Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Define a route for making predictions\n",
        "@app.route(\"/predict\", methods=[\"POST\"])\n",
        "def predict():\n",
        "    data = request.get_json()\n",
        "    budget = data[\"budget\"]\n",
        "\n",
        "    # Allocate the budget proportionally based on feature coefficients\n",
        "    budget_allocation = model.coef_ * budget\n",
        "\n",
        "    # Compute the predicted sales with the budget allocation\n",
        "    predicted_sales = model.predict(budget_allocation.reshape(1, -1))\n",
        "\n",
        "    # Compute the profit by subtracting the marketing budget from the predicted sales\n",
        "    profit = predicted_sales - budget\n",
        "\n",
        "    # Create a response JSON\n",
        "    response = {\n",
        "        \"predicted_sales\": predicted_sales.item(),\n",
        "        \"profit\": profit.item()\n",
        "    }\n",
        "\n",
        "    return jsonify(response)\n",
        "\n",
        "# Run the Flask app\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(host=\"0.0.0.0\", port=5000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYMPk8nZE00X",
        "outputId": "66408117-4c80-4622-c362-96bc15e71d5c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the Docker Image"
      ],
      "metadata": {
        "id": "lV6XtM8wG23T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docker build -t myapp ."
      ],
      "metadata": {
        "id": "BFgS3gegG_ID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the Docker container:"
      ],
      "metadata": {
        "id": "vhMlZRMEG5bH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docker run -p 5000:5000 myapp"
      ],
      "metadata": {
        "id": "k1sw_IUAGYPV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}